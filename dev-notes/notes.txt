DRIZZLE: 
drizzle install - https://orm.drizzle.team/docs/get-started-postgresql#postgresjs 
npm i drizzle-orm postgres // to follow WebDevSimplified tutorial, i am using Postgres.JS driver 
npm i -D drizzle-kit

- drizzle kit overview docs 
https://orm.drizzle.team/kit-docs/overview 

drizzle config 
https://orm.drizzle.team/kit-docs/config-reference 
https://orm.drizzle.team/kit-docs/upgrade-21#2-update-your-drizzleconfigts-file

https://orm.drizzle.team/kit-docs/config-reference#configuration

import { defineConfig } from "drizzle-kit";

export default defineConfig({
  dialect: "postgresql", //dialect is required 
  schema: "./src/drizzle/schema.ts",
  out: "./src/drizzle/migrations",
  // driver: "" drive is not required because Drizzle has 
  // native support for PostgreSQL with pg, postgres,
  // vercel-postgres, and neon drivers 
  dbCredentials: {
    url: process.env.DATABASE_URL as string,
  },
  verbose: true,//when running the migration, it will print out the SQL queries that are being executed
  strict: true,//
});

- drizzle STUDIO 
Studio requires drizzle config file with schema and dbCredentials provided.

commands: 
drizzle-kit studio
drizzle-kit studio --port 3000 ## custom port
drizzle-kit studio --host 0.0.0.0 ## custom host for studio server
drizzle-kit studio --verbose   ## log all sql statements


- drizzle kit docs 
migrations and schema configs 
multi project schemas 
SQL breakpoints 
Push and Pull 
https://orm.drizzle.team/kit-docs/conf

60 min tutorial 
https://www.youtube.com/watch?v=7-NZ0MlPpJA&t=57s&ab_channel=WebDevSimplified

comprehensive drizzle tutorial 
https://www.youtube.com/watch?v=fDjZOZ1Hgf8&list=PLhnVDNT5zYN8PLdYddaU3jiZXeOyehhoU&ab_channel=SakuraDev 


- setting up postgresql in a docker container 
https://www.youtube.com/watch?v=F8I3WYSAXYQ&t=5s&ab_channel=DenisMagda 



node and npm installation 

install git bash 

run the following command: curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.0/install.sh | bash 

if you get an error for missing bashrc file, open git bash: 
- create file: 
touch ~/.bashrc
- open the bashrc file 
nano ~/.bashrc
- add the following lines then save and exit nano 
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm 
- source the file to apply the changes 
source ~/.bashrc
- install nvm again 
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.0/install.sh | bash 
- install node 
nvm install node


- need to install nvm, npm, and node on c drive 
    -x first need to uninstall npm and node 
    - delete nvm 
      - rm -rf "$NVM_DIR"
      - remove the following from bashrc 
      export NVM_DIR="$HOME/.nvm"
      [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm
- need to put bashrc and bash profile in c drive 
    - delete bashrc and .bash_profile from hive drive 
    rm ~/.bash_profile
    rm ~/.bashrc
    - create them on c drive 
    touch /c/Users/nflores/.bashrc
    nano /c/Users/nflores/.bashrc
    
    export NVM_DIR="$HOME/.nvm"
    [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm

    source /c/Users/nflores/.bashrc
    
    touch /c/Users/nflores/.bash_profile
    nano /c/Users/nflores/.bash_profile
    source /c/Users/nflores/.bash_profile


------------ docker ------------

Pulling the PostgreSQL Image
When you pull the PostgreSQL image and run it directly using Docker commands, you are manually managing the container. 
This approach is straightforward but requires more manual steps to configure and manage the container.

docker pull postgres
docker run --name local-postgres -e POSTGRES_PASSWORD=example -p 5432:5432 -d postgres

Pros
Simplicity: Easy to understand and execute for simple use cases.
Direct Control: You have direct control over the container's lifecycle.

Cons
Manual Configuration: Requires manual setup and configuration for each container.
Limited Orchestration: Not suitable for managing multiple containers or complex setups.

Using Docker Compose
Docker Compose is a tool for defining and running multi-container Docker applications. It allows you to manage multiple 
services (containers) using a single YAML file (docker-compose.yml). This approach is more automated and scalable, 
making it easier to manage complex applications.

- Create a docker-compose.yml File in the root of directory:
    # version is no longer needed on Docker V2 projects which use 'docker compose' 
    version: '3.8' # version key specifies the version of the Docker Compose file format 

    services:                         # each service runs a specific docker image
      postgres:
        image: postgres:latest
        container_name: postgres-db   # optional custom name for container 
        environment:                  # config for db container will create 
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: example
          POSTGRES_DB: mydatabase     # name of the database to be created
        ports:                        # maps ports on the host to ports on the container 
          - "5432:5432"
        volumes:                      # Mounts host directories or named volumes into the container. 
          - postgres-data:/var/lib/postgresql/data  # specified directory inside the container 

    volumes:                          # declares a named volume 
      postgres-data:

- run: docker-compose up -d

First Run:

  - When you run docker-compose up -d for the first time, Docker creates the postgres-data volume.
  - The PostgreSQL container initializes and creates the database drizzle-pg as specified in the environment variables.

Subsequent Runs:

  - On subsequent runs, Docker reuses the existing postgres-data volume.
  - The database drizzle-pg already exists in the volume, so it is not recreated.
  - If you want to force the creation of a new database, you would need to remove 
  the volume with docker volume rm postgres-data before running docker-compose up -d again

Pros
- Automation: Automates the setup and configuration of multiple containers.
- Orchestration: Manages the lifecycle of multiple services, including dependencies.
- Reusability: The docker-compose.yml file can be reused and shared across different environments.
- Scalability: Easily scale services up or down.

Cons
- Complexity: Slightly more complex to set up initially compared to running a single container.
- Learning Curve: Requires understanding of Docker Compose syntax and concepts.

Summary
- Pulling the PostgreSQL Image: Suitable for simple, single-container setups. Requires manual configuration and management.
- Using Docker Compose: Ideal for complex, multi-container applications. Provides automation, orchestration, 
  and scalability through a single configuration file.

connecting to db:
  Host: localhost
  Port: 5432
  Username: postgres
  Password: <your_password>
GUI tools: pgAdmin, DBeaver
can use psql for command line interaction 
  - Execute SQL Commands: Run SQL queries and commands to interact with the database.
  - Database Management: Create, modify, and delete databases and database objects like tables, indexes, and views.
  - Scripting: Write and execute scripts to automate database tasks.
  - Interactive Mode: Provides an interactive shell for real-time database interaction.
  - Batch Mode: Execute commands from a file or standard input.
  - commands: 
    connect: psql -h <host> -U <username> -d <database> 
    once connected: you can run sql statement in terminal: SELECT * FROM mytable;  
    exit: \q

integrating db to node.js project: 
1. Install pg Package: In your Node.js project, install the pg package to interact with PostgreSQL:
  npm install pg
2. Create a Database Connection: Create a file (e.g., db.js) to manage the database connection:
  ----------
  // db.js
  const { Pool } = require('pg');

  const pool = new Pool({
    user: 'postgres',
    host: 'localhost',
    database: 'mydatabase',
    password: 'example',
    port: 5432,
  });

  module.exports = pool;
  ------------

3. Use the Database Connection: Use the connection in your application:
  -------------

  // example.js
  const pool = require('./db');

  pool.query('SELECT NOW()', (err, res) => {
    if (err) {
      console.error('Error executing query', err.stack);
    } else {
      console.log('Current time:', res.rows[0]);
    }
    pool.end();
  });

  -------------

volumes
  - Volumes in Docker are used to persist data generated by and used by Docker containers. 
  They are stored outside the container's filesystem, which means they are not affected by the 
  lifecycle of the container (e.g., when the container is stopped or removed, the data in the volume remains intact).

  - Creation: Volumes can be created explicitly using the docker volume create command or implicitly when declared in a docker-compose.yml file.
  - Mounting: Volumes are mounted into containers at specified paths. This is done using the volumes key in the docker-compose.yml file 
  or the -v flag in the docker run command.
  - Persistence: Data written to the volume is stored on the host machine and persists across container restarts and removals.
  - Sharing: Volumes can be shared between multiple containers, allowing them to read and write to the same data.

  - On a Windows machine, Docker volumes are typically stored in a specific directory managed by Docker. The default location is:
  C:\ProgramData\Docker\volumes
  - Each volume is stored in its own directory within this path. The directory name corresponds to the volume name or a unique 
  identifier if the volume was created without a specific name.

Commands 
docker-compose: This is the command used for Docker Compose v1. It is a standalone tool that you need to install separately from Docker.

docker compose: This is the command used for Docker Compose v2, which is integrated into the Docker CLI. It is available if you have Docker CLI v20.10.0 or later.

docker commands to run in project's root directory 
  - docker ps: check running containers 
  - docker compose ps                               : view running services 
  - docker compose logs                             : view logs for all services 
  - docker compose up -d --scale <service>=<number> : scale a service to a certain number of instances 
  - docker compose up -d                            : start all services, -d flag specifies 'detached mode' which means terminal will not be locked  
  - docker compose down                             : stop all running services 
  - docker volume create postgres-data              : create a volume 
  - docker volume ls                                : list volumes 
  - docker volume inspect postgres-data             : inspect a volume 
  - docker volume rm postgres-data                  : remove a volume 


Getting the database  URL 

get container name from config file or: 
docker compose ps

inspect container to get IPAddress 
docker inspect <container_name>

host = IPAddress
port = HostPort or found in config file 
  URL: "postgresql://<username>:<password>@<host>:<port>/<database_name>."
  URL: "postgresql://drizzle:dev@172.18.0.2:5432/drizzle-pg"

https://www.youtube.com/watch?v=xHg0IJDl1RY
in this tutorial, he puts localhost as the <host> and after the database name he specifies 
the schema: <database name>?schema=public

If container is running on my local machine, connect with localhost :  URL: "postgresql://drizzle:dev@localhost:5432/drizzle-pg"
If it is running on a specific server, use your server IP. (For Windows docker-machine you probably need to use 192.168.99.100).